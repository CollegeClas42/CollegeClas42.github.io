<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AI Resume Screening Still Has a Bias Problem (And It’s Not Going Away)</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header class="site-header">
    <h1>Applied AI Hiring & HR</h1>
    <nav class="nav">
      <a href="index.html">Home</a>
      <a href="about.html">About</a>
    </nav>
  </header>

  <main class="container">
    <h2>AI Resume Screening Still Has a Bias Problem (And It’s Not Going Away)</h2>
    <p class="post-date-page">January 24, 2026</p>

    <p>
      AI screening tools are supposed to make hiring easier, but bias is still a huge issue. A University of Washington study
      reported in 2024 showed that some resume screening AI can favor candidates who appear white and male, depending on how the
      system reads names and other cues.
    </p>

    <p>
      Even if an employer isn’t trying to discriminate, AI can still learn patterns from past hiring decisions and repeat the same
      unfair outcomes. This matters because screening is the first big “yes or no” step. If AI filters you out early, you might never
      even get to a real interview—even if you’re qualified.
    </p>

    <p>
      My take: AI should not be the final judge in hiring. At most, it should help organize applicants, not auto-reject people behind
      the scenes. If companies use AI screening, they need to audit it and keep real humans accountable. Faster hiring sounds nice, but
      it’s not worth it if the process becomes quietly unfair.
    </p>
  </main>

  <footer class="site-footer">
    <p>© 2026 Applied AI Hiring & HR</p>
  </footer>
</body>
</html>
